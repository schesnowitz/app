<ul>
  <li>test</li>
    <li>test1</li>
      <li>test2</li>
        <li>test3</li>
</ul>

require 'openai'

# Set up the OpenAI client
client = OpenAI::Client.new(
  api_key: "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"
)

# Use the client to generate a response
response = client.completion(
  model: "text-davinci-002",
  prompt: "What is the capital of France?",
  temperature: 0.5,
  max_tokens: 32,
  top_p: 1,
  frequency_penalty: 0,
  presence_penalty: 0
)

# Print the generated response
puts response.text

client = OpenAI::Client.new(access_token: "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")